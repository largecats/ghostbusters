{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import * # Functions written by team ghostbusters\n",
    "import seaborn as sns\n",
    "from category_encoders import TargetEncoder\n",
    "import networkx as nx\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>General Attributes</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Property type</h3>\n",
    "Ordinal encoding property_type based on EDA result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generalize property type\n",
    "\"\"\"\n",
    "df['general_property_type'] = df['property_type'].apply(generalize_property_type) # 3 general typesï¼š landed hdb condo\n",
    "\n",
    "\"\"\"\n",
    "Standardize property type\n",
    "\"\"\"\n",
    "df['property_type'] = df['property_type'].apply(standardize_property_type) # lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Property categori ordinal encoding\n",
    "The order of encoding follows the EDA results of price_sqft from small to large\n",
    "\"\"\"\n",
    "ordered_ppt_type = {\n",
    "\"hdb\":1, \n",
    "\"executive condo\":2, \"walk-up\":2,\"shophouse\":2,\n",
    "\"condo\":3,\"apartment\":3,\n",
    "\"townhouse\":4,\"terraced house\":4,\"landed\":4,\"cluster house\":4,\n",
    "\"corner terrace\":5,\n",
    "\"conservation house\":6,\n",
    "\"semi-detached house\":7,\n",
    "\"bungalow\":8,\n",
    "\"land only\":9,\n",
    " }\n",
    "df[\"property_type_ordinal\"] = df[\"property_type\"].replace(ordered_ppt_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Size_sqft</h3>\n",
    "Fill outlier with mean value based on general property types (hdb, condo, landed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan and outlier 28\n",
      "Nan and outlier after filled 0\n",
      "Num after clean 6966\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Clean size_sqft\n",
    "\"\"\"\n",
    "#   Find large outlier, transfrom small outlier to size square feet if can find corresponding data in the same property\n",
    "df.size_sqft = df.apply(lambda r: standardize_size(r, df, 400, 6000,'hdb'), axis=1)\n",
    "df.size_sqft = df.apply(lambda r: standardize_size(r, df, 400, 1000000,'condo'), axis=1)\n",
    "df.size_sqft = df.apply(lambda r: standardize_size(r, df, 400, 60000,'landed'), axis=1)\n",
    "print(\"Nan and outlier\", df.size_sqft.isna().sum())\n",
    "\n",
    "#   If fill na with mean size_sqft of general property_type (hdb, condo, landed)\n",
    "df[\"size_sqft\"] = df.groupby([\"general_property_type\"])[\"size_sqft\"].transform(lambda x: x.fillna(x.mean()))\n",
    "print(\"Nan and outlier after filled\", df.size_sqft.isna().sum())\n",
    "print('Num after clean', df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Num_beds</h3>\n",
    "Fill missing value following EDA observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null in num_beds: 35\n",
      "data num after cleaning: 6966\n",
      "Null in num_beds after cleaned: 0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Bed\n",
    "\"\"\"\n",
    "print('Null in num_beds:',len(df[df.num_beds.isnull()]))\n",
    "\n",
    "#   1. Set studio bed\n",
    "is_studio = df.title.str.contains('studio')# is studio\n",
    "is_null = df.num_beds.isnull() # num_beds is null\n",
    "is_small = df.size_sqft <=900 # is studio but not studio house\n",
    "df.loc[is_studio&is_null&is_small,\"num_beds\"] = 1\n",
    "\n",
    "#   2. Fill with information of the same property\n",
    "df['num_beds'] = df.groupby(['property_name','size_sqft'])['num_beds'].transform(lambda x: x.fillna(next(iter(x.mode()), np.nan)))\n",
    "\n",
    "#   3. Fill num_beds with hdb info, in comparison with other type of house, the floor plan and size of hdb is generally fiexed\n",
    "is_null = df.num_beds.isnull() # num_beds is null\n",
    "is_4rm = df.size_sqft > 1290 # Observation from EDA over 85% of 4 room larger than 1290 sqft\n",
    "is_2rm = df.size_sqft < 900 # Observation from EDA over 95% of 2 room smaller than 900 sqft\n",
    "is_hdb = df.general_property_type.str.contains(\"hdb\", na=False, case=False) # is hdb\n",
    "df.loc[is_hdb&is_null&is_4rm,'num_beds'] = 4\n",
    "df.loc[is_hdb&is_null&(~is_2rm)&(~is_4rm),'num_beds'] = 3\n",
    "df.loc[is_hdb&is_null&is_2rm,'num_beds'] = 2\n",
    "\n",
    "#   4. Fill the rest with mean based on size_sqft\n",
    "df[\"num_beds\"] = df.groupby([\"size_sqft\"])[\"num_beds\"].transform(lambda x: x.fillna(int(x.mean())))\n",
    "print('data num after cleaning:',df.shape[0])\n",
    "print('Null in num_beds after cleaned:',len(df[df.num_beds.isnull()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Num_baths</h3>\n",
    "Fill missing values, fill outlier and other missing data with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data num before cleaning: 6966\n",
      "Null in num_baths: 149\n",
      "data num after cleaning: 6966\n",
      "Null in num_baths after clean: 0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "baths\n",
    "\"\"\"\n",
    "print('data num before cleaning:',df.shape[0])\n",
    "print('Null in num_baths:',len(df[df.num_baths.isnull()]))\n",
    "\n",
    "#   1. Fill with information of the same property\n",
    "df['num_baths'] = df.groupby(['property_name','num_beds','size_sqft'])['num_baths'].transform(lambda x: x.fillna(next(iter(x.mode()), np.nan)))\n",
    "\n",
    "#  2. Fill with mode with corresponding num_beds\n",
    "df['num_baths'] = df.groupby(['num_beds','size_sqft'])[\"num_baths\"].transform(lambda x: x.fillna(next(iter(x.mode()), np.nan)))# Strict search with size_sqft\n",
    "df['num_baths'] = df.groupby(['num_beds'])[\"num_baths\"].transform(lambda x: x.fillna(next(iter(x.mode()), np.nan)))# Relax search only consider floor plan\n",
    "print('data num after cleaning:',df.shape[0])\n",
    "print('Null in num_baths after clean:',len(df[df.num_baths.isnull()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Remove outliers regarding num_beds and num_baths</h3>\n",
    "Find outlier based on bed2bath ratio, fill outlier with reference values from same property or mean based on size and floor plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null in num_beds after clean: 0\n",
      "Null in num_baths after clean: 0\n"
     ]
    }
   ],
   "source": [
    "##  1. Try filling noisy data with information of the same property, outliers are defined by based on boxplot result\n",
    "df_noise = df.copy()\n",
    "df_noise['bed2bath'] =df_noise['num_beds']/df_noise['num_baths']\n",
    "df_noise_cleaned = df_noise.apply(lambda r: standardize_bednbath(r, df_noise, 0.4,3), axis=1)\n",
    "\n",
    "df_noise_arr = np.array([*df_noise_cleaned])\n",
    "df['num_beds'] = df_noise_arr[:,0]\n",
    "df['num_baths'] = df_noise_arr[:,1]\n",
    "# 2. Fill NaN with mean based on size and floor plan\n",
    "df[\"num_beds\"] = df.groupby([\"size_sqft\"])[\"num_beds\"].transform(lambda x: x.fillna(int(x.mean())))\n",
    "df['num_baths'] = df.groupby(['num_beds'])[\"num_baths\"].transform(lambda x: x.fillna(next(iter(x.mode()), np.nan)))\n",
    "print('Null in num_beds after clean:',df.num_beds.isna().sum())\n",
    "print('Null in num_baths after clean:',df.num_baths.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Built Year</h3>\n",
    "Fill missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Built year \n",
    "\"\"\"\n",
    "##  Fill missing value based on mean values of each general property type 'hdb' 'condo' 'landed'\n",
    "year_group = df.groupby(by = ['general_property_type'])['built_year'].transform(lambda x: int(x.mean()))\n",
    "df['built_year'] = df['built_year'].fillna(year_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Tenure </h3>\n",
    "Group tenure years, ordinal encoding based on EDA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tenure\n",
    "\"\"\"\n",
    "# Genralize tenur into 3 groups 'Nan', '99~110 year' ,'900+ year', 'freehold'\n",
    "# Ordinal encoding following EDA results\n",
    "df['tenure_group'] = df['tenure'].apply(standardize_tenure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Target encoding per price based on subzone</h3>\n",
    "Using target encoding information from cleaned train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "load reference train data\n",
    "\"\"\"\n",
    "df_train_ref = pd.read_csv('./data/train_final_complete_nodrop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Subzone name encode\n",
    "\"\"\"\n",
    "# Find corresponding entries in train data to fill test data\n",
    "df['subzone_per_price_encoded'] = df.apply(lambda r: set_encoded_with_csv(r, df_train_ref, 'subzone_per_price_encoded',\"subzone\"),axis =1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Auxiliary Data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>MRT</h3>\n",
    "find 50 mrt stations with the highest in/out degree centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_mrt_connections = pd.read_csv('data/auxiliary-data/sg-mrt-connections.csv')\n",
    "df_mrt = pd.read_csv('data/auxiliary-data/sg-mrt-stations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dhoby ghaut (0.03968)\n",
      "macpherson (0.03175)\n",
      "little india (0.03175)\n",
      "buona vista (0.03175)\n",
      "chinatown (0.03175)\n",
      "['dhoby ghaut', 'macpherson', 'little india', 'buona vista', 'chinatown', 'botanic gardens', 'newton', 'serangoon', 'bugis', 'bishan', 'outram park', 'woodlands', 'promenade', 'paya lebar', 'tampines', 'raffles place', 'caldecott', 'expo', 'tanah merah', 'jurong east', 'bayfront', 'marina bay', 'city hall', 'tanjong pagar', 'bright hill', 'mayflower', 'mattar', 'rochor', 'one-north', 'kent ridge', 'downtown', 'telok ayer', 'ubi', 'dover', 'farrer park', 'boon keng', 'clarke quay', 'kaki bukit', 'farrer road', 'holland village', 'harbourfront', 'telok blangah', 'marsiling', 'kranji', 'sengkang', 'buangkok', 'stevens', 'bedok', 'yew tee', 'bukit batok']\n"
     ]
    }
   ],
   "source": [
    "# Find important statinons \n",
    "G_undirected = nx.Graph()\n",
    "\n",
    "for idx, row in df_mrt_connections.iterrows():\n",
    "    G_undirected.add_edge(row['to'], row['from'])\n",
    "\n",
    "nx_degree_scores = nx.algorithms.centrality.degree_centrality(G_undirected)\n",
    "\n",
    "ordered_degree_scores = sorted(nx_degree_scores.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "for station, score in ordered_degree_scores[:5]:\n",
    "    print('{} ({:.5f})'.format(station, score))\n",
    "\n",
    "important_mrt_stations = [entry[0] for entry in ordered_degree_scores[:50]]\n",
    "print(important_mrt_stations)\n",
    "\n",
    "df_important_mrt = df_mrt[df_mrt['name'].isin(important_mrt_stations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_distance_to_nearest_mrt(df_important_mrt, df, 'dist_to_nearest_important_mrt')\n",
    "df['dist_to_nearest_important_mrt_rounded'] = df['dist_to_nearest_important_mrt'].round(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Shopping Mall</h3>\n",
    "Find number of shopping malls within 300 m of the property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Load Data\n",
    "df_shopping_mall = pd.read_csv('./data/auxiliary-data/sg-shopping-malls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Add number of nearby shopping malls\n",
    "df = add_number_of_nearby_shopping_malls(df_shopping_mall,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Schools</h3>\n",
    "Find number of nearby schools within 1 km of the property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_primary_schools = pd.read_csv('./data/auxiliary-data/sg-primary-schools.csv')\n",
    "df_secondary_schools = pd.read_csv('./data/auxiliary-data/sg-secondary-schools.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_number_of_nearby_primary_schools(df_primary_schools, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_number_of_nearby_secondary_schools(df_secondary_schools, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.num_baths.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Commertial Centre</h3>\n",
    "Find name of nearest commercial centre(type: BN and CR) within 10 km of the property.\n",
    "Ordinal encoding the name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_cc = pd.read_csv('./data/auxiliary-data/sg-commerical-centres.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find name of nearest 'BN' commertial centre within 10 km of the property\n",
    "df= add_name_of_nearest_commercial_centre_by_type(df,df_cc,'BN',10)\n",
    "# Find name of nearest 'CR' commertial centre within 10 km of the property\n",
    "df = add_name_of_nearest_commercial_centre_by_type(df,df_cc,'CR',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Categorical encoding BN\n",
    "ordered_BN = {\n",
    "'Novena':9,\n",
    "'Alexandra':8,\n",
    " 'Buona Vista':7,\n",
    " 'Paya Lebar Central':6,'Serangoon':5,\n",
    " 'Bishan':4,\n",
    " 'Changi East Urban District':3,\n",
    " 'Tao Payoh':2,\n",
    " 'None':1\n",
    " }\n",
    "df[\"name_of_nearest_BN_ordinal\"] = df[\"name_of_nearest_BN\"].replace(ordered_BN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Categorical encoding CR\n",
    "ordered_CR = {\n",
    "'Central Business District':5,\n",
    " 'Jurong Lake District':4,\n",
    " 'Tampines Regional Centre':3,\n",
    " 'Seletar Regional Centre':2,\n",
    " 'Woodlands Regional Centre':1\n",
    " }\n",
    "df[\"name_of_nearest_CR_ordinal\"] = df[\"name_of_nearest_CR\"].replace(ordered_CR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Fill na (subzone not appeared in train set) using property near certain CR\n",
    "df['subzone_per_price_encoded'] = df.groupby([\"name_of_nearest_CR\"])['subzone_per_price_encoded'].transform(lambda x: x.fillna(next(iter(x.mode()), np.nan)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Drop Columns</h2>\n",
    "Drop features that are not useful for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df[['built_year', 'num_beds', 'num_baths', 'lat', 'lng', 'size_sqft',\n",
    "                    'tenure_group', 'subzone_per_price_encoded',\n",
    "                    'property_type_ordinal',\n",
    "                    #mrt\n",
    "                    'dist_to_nearest_important_mrt_rounded',\n",
    "                    #schools\n",
    "                    'number_of_nearby_primary_schools', \n",
    "                    'number_of_nearby_secondary_schools', \n",
    "                    #shopping mall\n",
    "                    'number_of_nearby_shopping_malls',\n",
    "                    #CR\n",
    "                    'name_of_nearest_BN_ordinal',\n",
    "                    'name_of_nearest_CR_ordinal'\n",
    "                    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check is still contains missing values\n",
    "for col in df_final.columns:\n",
    "    if df_final[col].isna().sum():\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Save to CSV</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testset CSV for final prediction\n",
    "df_final.to_csv('./data/test_final_complete_cleaned.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cceb2fdb6d0d49712663a09c62496ac932ce62398c41e486b12dcc6178307130"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
