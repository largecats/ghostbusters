{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Stacking model</h1>\n",
    "This notebook contains code for stacking model, which combines 3 models with best performance on 30% test set: Random Forest Regressor, Gradient Boosting Regressor, and Multilayer Perceptron. We get best models & parameters by pretraining them separately. Their RMSE on price/sqft(per_price) will be converted to their respective weights for final stacking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for MLP\n",
    "from mlp import *\n",
    "import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "def set_seeds(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "#8\n",
    "set_seeds(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_predicted(predicted):\n",
    "  df_predicted = pd.DataFrame(predicted)\n",
    "  df_predicted.columns = ['Predicted']\n",
    "  df_predicted['Id'] = df_predicted.index\n",
    "  df_predicted = df_predicted.reindex(columns=['Id', 'Predicted'])\n",
    "  return df_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_train = pd.read_csv('train_final_complete.csv')\n",
    "df_test = pd.read_csv('test_final_complete_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['built_year', 'num_beds', 'num_baths', 'lat', 'lng', 'size_sqft',\n",
    "                    'tenure_group', 'subzone_per_price_encoded',\n",
    "                    'property_type_ordinal',\n",
    "                    #mrt\n",
    "                    'dist_to_nearest_important_mrt_rounded',\n",
    "                    #schools\n",
    "                    'number_of_nearby_primary_schools', \n",
    "                    'number_of_nearby_secondary_schools', \n",
    "                    #shopping mall\n",
    "                    'number_of_nearby_shopping_malls',\n",
    "                    #CR\n",
    "                    'name_of_nearest_BN_ordinal',\n",
    "                    'name_of_nearest_CR_ordinal']\n",
    "X_train = df_train[feature_list]\n",
    "y_train = df_train['per_price']\n",
    "size_sqft_train = df_train['size_sqft']\n",
    "\n",
    "X_test = df_test[feature_list]\n",
    "X_train = X_train.reindex(columns=list(X_test.columns)) # unify column order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Random Forest </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=50, max_features=8)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit Model\n",
    "random_forest_model = RandomForestRegressor(max_depth=50,max_features=8,n_estimators=100)\n",
    "random_forest_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor RMSE: 55343.215727600356\n"
     ]
    }
   ],
   "source": [
    "#Get RMSE prediction on train set\n",
    "y_pred = random_forest_model.predict(X_train)\n",
    "random_forest_score = mean_squared_error(y_train,y_pred)\n",
    "print('RandomForestRegressor RMSE:', random_forest_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Gradient Boosting </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.5, max_depth=4, n_estimators=400)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit model\n",
    "gradient_boosting_model = GradientBoostingRegressor(learning_rate=0.5,max_depth=4,n_estimators=400)\n",
    "gradient_boosting_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor RMSE: 50975.49296366274\n"
     ]
    }
   ],
   "source": [
    "#Get RMSE prediction on train set\n",
    "y_pred = gradient_boosting_model.predict(X_train)\n",
    "gradient_boosting_score = mean_squared_error(y_train,y_pred)\n",
    "print('GradientBoostingRegressor RMSE:', gradient_boosting_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Multilayer Perceptron</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_predict(model,data):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.load_state_dict(torch.load('./model.pth',map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    prices = []\n",
    "    test_dataset = houseTestDataset(data)\n",
    "    with torch.no_grad():\n",
    "        for step, data in enumerate(tqdm(test_dataset)):\n",
    "            input_tensor = data.to(device)\n",
    "            pred = model(input_tensor).detach().cpu().item()\n",
    "            prices.append(pred)\n",
    "    res = np.asarray(prices)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize feature data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_normalized = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20003/20003 [00:01<00:00, 13543.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP RMSE: 99874.31874259491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = BaseNN(len(feature_list))\n",
    "y_pred = mlp_predict(model,X_train_normalized)\n",
    "#mlp_score = mean_squared_error(y_train*size_sqft_train,y_pred*size_sqft_train)\n",
    "mlp_score = mean_squared_error(y_train,y_pred)\n",
    "print('MLP RMSE:', mlp_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Stack Results </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Random forest + gradient boosting + mlp </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest weight 0.3788149426695488 GradientBoosting weight 0.41127286611909625 MLP weight: 0.2099121912113549\n"
     ]
    }
   ],
   "source": [
    "# Calculate weight for each model\n",
    "sum_scores = (1/random_forest_score)+(1/gradient_boosting_score)+(1/mlp_score)\n",
    "random_forest_weight = (1/random_forest_score)/sum_scores \n",
    "gradient_boosting_weight = (1/gradient_boosting_score)/sum_scores\n",
    "mlp_weight = 1 - random_forest_weight - gradient_boosting_weight\n",
    "print('Random Forest weight',random_forest_weight,'GradientBoosting weight',gradient_boosting_weight,'MLP weight:', mlp_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6966/6966 [00:00<00:00, 14271.31it/s]\n"
     ]
    }
   ],
   "source": [
    "random_forest_prediction = random_forest_model.predict(X_test)\n",
    "gradient_boosting_prediction = gradient_boosting_model.predict(X_test)\n",
    "\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "mlp_prediction = mlp_predict(model,X_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction = (random_forest_weight*random_forest_prediction + gradient_boosting_weight * gradient_boosting_prediction + mlp_weight * mlp_prediction)*df_test.size_sqft\n",
    "df_pred = format_predicted(final_prediction)\n",
    "df_pred.to_csv('./stacking_pred.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Random forest + gradient boosting </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest weight 0.47945929358199335 GradientBoosting weight 0.5205407064180066\n"
     ]
    }
   ],
   "source": [
    "sum_scores = (1/random_forest_score)+(1/gradient_boosting_score)\n",
    "random_forest_weight = (1/random_forest_score)/sum_scores \n",
    "gradient_boosting_weight = 1-random_forest_weight\n",
    "print('Random Forest weight',random_forest_weight,'GradientBoosting weight',gradient_boosting_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction = (random_forest_weight*random_forest_prediction + gradient_boosting_weight * gradient_boosting_prediction)*df_test.size_sqft\n",
    "df_pred = format_predicted(final_prediction)\n",
    "df_pred.to_csv('./stacking_pred_nomlp.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cceb2fdb6d0d49712663a09c62496ac932ce62398c41e486b12dcc6178307130"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
